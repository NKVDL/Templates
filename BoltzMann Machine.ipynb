{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boltzmann machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jul 13 20:27:11 2018\n",
    "\n",
    "@author: NVDL\n",
    "\n",
    "Boltzmann machine to predict rating of movies based on customer ratings.\n",
    "\"\"\"\n",
    "###Part 1 - Importing \n",
    "#Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "movies = pd.read_csv('/Users/NVDL/Code/Practice_/Data/Math/Ranking/Movies/ml-1m/movies.dat',\n",
    "                     sep='::',\n",
    "                     header= None, \n",
    "                     engine = 'python', \n",
    "                     encoding ='latin-1')\n",
    "\n",
    "users = pd.read_csv('/Users/NVDL/Code/Practice_/Data/Math/Ranking/Movies/ml-1m/users.dat',\n",
    "                     sep='::',\n",
    "                     header= None, \n",
    "                     engine = 'python', \n",
    "                     encoding ='latin-1')\n",
    "\n",
    "ratings = pd.read_csv('/Users/NVDL/Code/Practice_/Data/Math/Ranking/Movies/ml-1m/ratings.dat',\n",
    "                     sep='::',\n",
    "                     header= None, \n",
    "                     engine = 'python', \n",
    "                     encoding ='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                   1                             2\n",
       "0  1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1  2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2  3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3  4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4  5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1  2          3\n",
       "0  1  1193  5  978300760\n",
       "1  1   661  3  978302109\n",
       "2  1   914  3  978301968\n",
       "3  1  3408  4  978300275\n",
       "4  1  2355  5  978824291"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1   2   3      4\n",
       "0  1  F   1  10  48067\n",
       "1  2  M  56  16  70072\n",
       "2  3  M  25  15  55117\n",
       "3  4  M  45   7  02460\n",
       "4  5  M  25  20  55455"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 2 - Preprocessing train/test set\n",
    "#Preparing the training set \n",
    "training_set = pd.read_csv('/Users/NVDL/Code/Practice_/Data/Math/Ranking/Movies/ml-100k/u1.base',\n",
    "                           delimiter = '\\t') #80% of total set \n",
    "#Convert df training_set to array\n",
    "training_set = np.array(training_set, dtype = 'int')\n",
    "\n",
    "#Preparing the the test set\n",
    "test_set = pd.read_csv('/Users/NVDL/Code/Practice_/Data/Math/Ranking/Movies/ml-100k/u1.test',\n",
    "                           delimiter = '\\t') #20% of total set \n",
    "#Convert df test_set to array\n",
    "test_set = np.array(test_set, dtype = 'int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,         2,         3, 876893171],\n",
       "       [        1,         3,         4, 878542960],\n",
       "       [        1,         4,         3, 876893119],\n",
       "       ...,\n",
       "       [      943,      1188,         3, 888640250],\n",
       "       [      943,      1228,         3, 888640275],\n",
       "       [      943,      1330,         3, 888692465]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,        10,         3, 875693118],\n",
       "       [        1,        12,         5, 878542960],\n",
       "       [        1,        14,         5, 874965706],\n",
       "       ...,\n",
       "       [      459,       934,         3, 879563639],\n",
       "       [      460,        10,         3, 882912371],\n",
       "       [      462,       682,         5, 886365231]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add variable to confirm # of customers and # of movies. To do this we add the \n",
    "maximum values of the columns of the training_set and test_set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the number of users and movies\n",
    "num_users = int(max(max(training_set[:,0]), max(test_set[:,0]))) #first column, maximum user id\n",
    "num_movies = int(max(max(training_set[:,1]), max(test_set[:,1]))) #first column, no. of movies"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "max(training_set[:,0] = 943 \n",
    "max(test_set[:,0]) = 462\n",
    "max(training_set[:,1]) = 1682\n",
    "max(test_set[:,1]) = 1591 \n",
    "\n",
    "num_users = 943\n",
    "num_movies = 1682 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting data into array with users in lines \n",
    "#and movies in columns (943 list of users with list of 1682 movies usersrating)\n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, num_users + 1): #1, up to [shift data 1+] num_users \n",
    "        id_movies = data[:,1][data[:,0] == id_users] #movie of users\n",
    "        id_ratings = data[:,2][data[:,0] == id_users] #movie rating of users\n",
    "        ratings = np.zeros(num_movies)\n",
    "        ratings[id_movies - 1] = id_ratings \n",
    "        new_data.append(list(ratings))\n",
    "    return new_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert training set to return list of customers with lists of rating per movie\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the dataset into Torch tensors\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)    \n",
    "\n",
    "#Converting ratings into binary ratings of training set\n",
    "training_set[training_set == 0] = -1 #all zeros to -1  \n",
    "training_set[training_set == 1] = 0  #all 1 to 0\n",
    "training_set[training_set == 2] = 0  #all 2 to 0  \n",
    "training_set[training_set >= 3] = 1 #num>2 = 1     \n",
    "\n",
    "#Converting ratings into binary ratings of test set\n",
    "test_set[test_set == 0] = -1 #all zeros to -1  \n",
    "test_set[test_set == 1] = 0  #all 1 to 0\n",
    "test_set[test_set == 2] = 0  #all 2 to 0  \n",
    "test_set[test_set >= 3] = 1 #num>2 = 1     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to create a class with three functions for the Restricted Boltzmann\n",
    "Machine which it will obey.\n",
    "        \n",
    "\n",
    "1. Initialise tensors of all weights and biases of the  visible nodes and\n",
    "   hidden nodes. Add weight parameter of the probabilities of the visible \n",
    "   nodes according to the hidden nodes.\n",
    "2. Sample hidden nodes\n",
    "   For every each hidden node activate them for a given probablity given v.\n",
    "   In which the activation is a linear function of the neurons where the \n",
    "   coefficients are the functions. So, the activation is probability that the\n",
    "   hidden node will be activated according to the value of the visible node. \n",
    "   The activation is returned as a sigmoid function. But we're making a \n",
    "   Bernoulli RBM. p[h|v] is vector of nh elements, each element corresponds to \n",
    "   each hidden node. We use this probabilities to sample activation of each \n",
    "   hidden node, depending on p[h|v] for v. If randn < 0.7 = activate neuron, \n",
    "   and if randn > 0.7 = not activate neuron. Obtain vector with a binary outcome \n",
    "   to list which hidden nodes activated or not activated.\n",
    "3. Sample visible nodes.\n",
    "   If randn < 0.25 = activate neuron, \n",
    "   and if randn > 0.25 = not activate neuron. Obtain vector with a binary outcome \n",
    "   to list which hidden nodes activated or not activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the architecture of the Neural Network\n",
    "class RBM():\n",
    "    def __init__(self, nv, nh):   \n",
    "        self.W = torch.randn(nh,nv) ##add weight parameter of the probabilities of the visible/hidden nodes\n",
    "        self.a = torch.randn(1, nh) ##bias for hidden nodes, additional element corresponding to current batch \n",
    "        self.b = torch.randn(1, nv) ##bias for visible nodes, additional element corresponding to current batch \n",
    "        \n",
    "    def sample_h(self, x): #x is visible neuron's v in the probabilites p[h|v] = sigmoid[wx*a] \n",
    "        wx = torch.mm(x, self.W.t()) #product of tensor (nv,nh) * p[h|v]\n",
    "        activation = wx + self.a.expand_as(wx) # wx++bias  \n",
    "        p_h_given_v = torch.sigmoid(activation) #sigmoid of the activation = #i'th vector gives probability of hidden node activation for i'th vector\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)  #Bernoulli samples\n",
    "    \n",
    "    def sample_v(self, y): #probabilities visible node = 1 given probablilites hidden nodes p[v|h] \n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy) # +bias of visible nodes  \n",
    "        p_v_given_h = torch.sigmoid(activation)  \n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)  #Bernoulli sampling\n",
    "    \n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t() #update weights\n",
    "        self.b += torch.sum((v0-vk), 0) #update bias for visible nodes\n",
    "        self.a += torch.sum((ph0-phk), 0) #update bias for hidden nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL-divergence to approximate loglikelikhood gradient. RBM-model is an energy\n",
    "function that depends on the weights of the tensors we try to minimize. This \n",
    "is a probabliblistic graphical model to maximise the loglikelihood and minimise\n",
    "the energy of the energy state. Therefore we need to compute the gradient, which is computing \n",
    "demanding. So we approximate the gradient with Gibbs sampling as following :\n",
    "    1. Input vector V[0]\n",
    "    2. Based on probabilities p[h|0] we sample hidden nodes = h1\n",
    "    3. We sample visible nodes with activation p[v|h1] = v1\n",
    "    4. Sample hidden nodes with activation p[h1|v1] = h2\n",
    "    5. k-times.... \n",
    "\n",
    "Contrasted convergence algorithm - Each round is 1 Gibbs sample (Gibbs Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = len(training_set[0]) #first line of training set with x features = # of number of visible nodes\n",
    "nh = 100 #Number of preferred features out of all 'movies'\n",
    "batch_size = 100 #update weights after nth round\n",
    "rbm = RBM(nv,nh) #Create model based on architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Model now created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1loss: tensor(0.3548)\n",
      "epoch: 2loss: tensor(0.2550)\n",
      "epoch: 3loss: tensor(0.2468)\n",
      "epoch: 4loss: tensor(0.2515)\n",
      "epoch: 5loss: tensor(0.2484)\n",
      "epoch: 6loss: tensor(0.2494)\n",
      "epoch: 7loss: tensor(0.2495)\n",
      "epoch: 8loss: tensor(0.2461)\n",
      "epoch: 9loss: tensor(0.2479)\n",
      "epoch: 10loss: tensor(0.2462)\n"
     ]
    }
   ],
   "source": [
    "### Part - 3 Train the Restricted Boltzman Machine\n",
    "epochs = 10 #Binary outcome and 934 observations\n",
    "for epoch in range(1, epochs +1): #+1 because upper bound not included\n",
    "    train_loss = 0\n",
    "    s = 0. #Normalise the train loss by dividing loss w/ counter s \n",
    "    for id_user in range(0, num_users - batch_size, batch_size): #Users per batch \n",
    "        vk = training_set[id_user:id_user+batch_size] #Input that gets updated, vector output of k steps\n",
    "        v0 = training_set[id_user:id_user+batch_size] #Target variable to calculate loss\n",
    "        #p(movie = rating 1| rating of consumer)\n",
    "        ph0,_ = rbm.sample_h(v0) #p(hidden node=1|target rating)\n",
    "        \n",
    "        #Loop model over k iterations for convergence\n",
    "        for k in range(10):\n",
    "            _,hk = rbm.sample_h(vk) #p(hidden node|visible node)\n",
    "            _,vk = rbm.sample_v(hk) #p(visible node|hidden node) k = 10\n",
    "            \n",
    "            #Approximate the gradient to update weights and biases with vk\n",
    "            vk[v0<0] = v0[v0<0] \n",
    "        #Compute phk --> Class;train(parameters)\n",
    "        phk,_ = rbm.sample_h(vk) #apply to last step of visible node sampling\n",
    "        #Train the Restricted Boltzmann Machine\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        #Update the train loss\n",
    "        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0])) #Include only existing ratings in training\n",
    "        #Add +1 for normaliser\n",
    "        s += 1.\n",
    "    print('epoch: '+str(epoch) +'loss: '+str(train_loss/s))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restricted Boltzmann Machine now trained. 3 out of 4 times we make a good prediction for the next movie rating for a user in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: tensor(0.2692)\n"
     ]
    }
   ],
   "source": [
    "### Part - 4 Test the Restricted Boltzman Machine\n",
    "test_loss = 0\n",
    "s = 0. #Normalise the train loss by dividing loss w/ counter s \n",
    "for id_user in range(num_users): #Users per batch \n",
    "    v = training_set[id_user:id_user+1] #Vector input of output RBM on test_set \n",
    "    vt = test_set[id_user:id_user+1] #Target variable to calculate loss\n",
    "             \n",
    "    #Predict next energy state \n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _,h = rbm.sample_h(v) #p(hidden node|visible node) - Sample hidden node\n",
    "        _,v = rbm.sample_v(h) #p(visible node|hidden node) - Sample visible node\n",
    "        #Update the train loss\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0])) #Avg.Distance\n",
    "        #Add +1 for normaliser\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2158)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(123.5720)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25118"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "u = np.random.choice([0,1], 100000)\n",
    "v = np.random.choice([0,1], 100000)\n",
    "u[:50000] = v[:50000]\n",
    "sum(u==v)/float(len(u)) # -> you get 0.75\n",
    "np.mean(np.abs(u-v)) # -> you get 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
